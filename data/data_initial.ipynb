{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CURTAINs\n",
    "\n",
    "<img src=\"../Curtains.png\" alt=\"Drawing\" style=\"width: 300px;\" align=\"left\"/>\n",
    "\n",
    "<br>\n",
    "<p>\n",
    "Welcome to the CURTAINs project, all windows need curtains.\n",
    "\n",
    "Using sidebands to extrapolate to the signal region in a sliding window anomaly detection hunt.\n",
    "</p>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Having a look at our test dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets = pd.read_hdf('/srv/beegfs/scratch/groups/dpnc/atlas/AnomalousJets/final_jj_1MEvents_substructure.h5','jets')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop events with nan, these have <3 constituents which renders tau3 nonsensical (how can you split a jet into three prongs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets = jets.dropna()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These quantiles were calculated over all jets and their mass, it was split into ten ~equal bins of 10k.\n",
    "\n",
    "We can see that after removing nan events we lose a chunk from the first bin (no prob) and then they fluctuate a bit, but it's still roughly a 10% share of jets in each mass bin"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantiles = ['mass_q{}'.format(i) for i in range (10)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets[quantiles].mean()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looking at the distributions for the mass quantiles.\n",
    "\n",
    "Again, for the actual use case we would look in narrower windows and not based on event fractions but we're playing with low statistics here.\n",
    "\n",
    "In data we will deal with O(1e7) events at least"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('plasma')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "m_vals,_=np.histogram(jets.m,weights=jets[q].values/np.sum(jets[q].values),bins=m_bins)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(nrows=2,ncols=3)\n",
    "fig.set_size_inches(18,9)\n",
    "m_bins = np.arange(0,100,2)\n",
    "m_summed = np.zeros(len(m_bins)-1)\n",
    "for i,q in enumerate(quantiles):\n",
    "    m_vals,_=np.histogram(jets.m,weights=jets[q].values/np.sum(jets[q].values),bins=m_bins)\n",
    "#     m_vals,_=np.histogram(jets.m,weights=jets[q].values,bins=m_bins)\n",
    "    axes[0][0].bar((m_bins[1:]+m_bins[:-1])/2,m_vals,(m_bins[1:]-m_bins[:-1]),label=q,color=cmap(i/10.),bottom=m_summed)\n",
    "    m_summed += m_vals\n",
    "    axes[0][1].hist(jets.pt,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(450,1200,50),histtype='step',color=cmap(i/10.))\n",
    "    axes[0][2].hist(jets.e,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(400,1500,100),histtype='step',color=cmap(i/10.))\n",
    "\n",
    "    \n",
    "    axes[1][0].hist(jets.tau2s/jets.taus,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(0,1.5,0.1),histtype='step',color=cmap(i/10.))\n",
    "    axes[1][1].hist(jets.tau3s/jets.tau2s,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(0,1.5,0.1),histtype='step',color=cmap(i/10.))\n",
    "    axes[1][2].hist(jets.d23s,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(0,50,2),histtype='step',color=cmap(i/10.))\n",
    "\n",
    "axes[0][0].step(m_bins, np.insert(m_summed,0,m_summed[0]), 'k', linestyle='-',lw=0.5,where='pre')\n",
    "axes[0][1].set_xlabel('jet pT [GeV]')\n",
    "axes[0][2].set_xlabel('jet E [GeV]')\n",
    "axes[0][0].set_xlabel('jet M [GeV]')\n",
    "axes[0][0].semilogy()\n",
    "axes[0][0].semilogx()\n",
    "axes[0][0].set_ylim(0.0001,1.0)\n",
    "axes[1][0].set_xlabel('tau21')\n",
    "axes[1][1].set_xlabel('tau32')\n",
    "axes[1][2].set_xlabel('d23s')\n",
    "axes[0][0].legend(loc='best')\n",
    "for ax,ax2 in axes[0],axes[1]:\n",
    "    ax.set_ylabel('Normalised Entries')\n",
    "    ax2.set_ylabel('Normalised Entries')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig,axes=plt.subplots(nrows=2,ncols=3)\n",
    "fig.set_size_inches(18,9)\n",
    "m_bins = np.arange(0,20,1)\n",
    "m_summed = np.zeros(len(m_bins)-1)\n",
    "for i,q in enumerate(quantiles[1:5]):\n",
    "    axes[0][1].hist(jets.pt,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(450,1200,50),histtype='step',color=cmap(i/4.))\n",
    "    axes[0][2].hist(jets.e,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(400,1500,100),histtype='step',color=cmap(i/4.))\n",
    "    m_vals,_=np.histogram(jets.m,weights=jets[q].values/np.sum(jets[q].values),bins=m_bins)\n",
    "#     m_vals,_=np.histogram(jets.m,weights=jets[q].values,bins=m_bins)\n",
    "    axes[0][0].bar((m_bins[1:]+m_bins[:-1])/2,m_vals,(m_bins[1:]-m_bins[:-1]),label=q,color=cmap(i/4.),bottom=m_summed)\n",
    "    m_summed += m_vals\n",
    "    axes[1][0].hist(jets.tau2s/jets.taus,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(0,1.5,0.1),histtype='step',color=cmap(i/4.))\n",
    "    axes[1][1].hist(jets.tau3s/jets.tau2s,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(0,1.5,0.1),histtype='step',color=cmap(i/4.))\n",
    "    axes[1][2].hist(jets.d23s,weights=jets[q].values/np.sum(jets[q].values),label=q,bins=np.arange(0,50,2),histtype='step',color=cmap(i/4.))\n",
    "\n",
    "axes[0][0].step(m_bins, np.insert(m_summed,0,m_summed[0]), 'k', linestyle='-',lw=0.5,where='pre')\n",
    "axes[0][0].set_ylim(0,0.7)\n",
    "axes[0][1].set_xlabel('jet pT [GeV]')\n",
    "axes[0][2].set_xlabel('jet E [GeV]')\n",
    "axes[0][0].set_xlabel('jet M [GeV]')\n",
    "\n",
    "axes[1][0].set_xlabel('tau21')\n",
    "axes[1][1].set_xlabel('tau32')\n",
    "axes[1][2].set_xlabel('d23s')\n",
    "axes[0][0].legend(loc='best')\n",
    "for ax,ax2 in axes[0],axes[1]:\n",
    "    ax.set_ylabel('Normalised Entries')\n",
    "    ax2.set_ylabel('Normalised Entries')\n",
    "# axes[0][0].set_ylabel('Normalised Entries')\n",
    "# axes[1][0].set_ylabel('Normalised Entries')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above case we would probably look for windows of around 10 GeV in width, but again, we want a proof of principle on small statistics that at least training the network is doable.\n",
    "\n",
    "Focusing on tau32 and tau21 for now, we can also add d23s in there.\n",
    "\n",
    "We will want to split into train/val datasets. When it comes to the network because our final application will not even include SB1<->SB2 but SB1->SR<-SB2 we will be able to reuse all the data used for training in evaluation and in validation in other windows (wider side band regions)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets['tau32'] = jets.tau3s / jets.tau2s\n",
    "jets['tau21'] = jets.tau2s / jets.taus"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jets[jets[quantiles[2]]==1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Just taking two quantiles for now, 2 and 4, assuming quantile 3 is now our signal region.\n",
    "We have very few events to play with so we can't have a very expressionful network, but the transformation should be minor.\n",
    "\n",
    "\n",
    "But something we should check is: if we are going to use an optimal transport loss to go from low mass -> high mass in a flow network, let's first check that our events of similar mass are \"closer\" to oneanother than they are to the target."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = jets[jets[quantiles[2]]==1][['m','pt','e','tau32','tau21','d23s']]\n",
    "y_train = jets[jets[quantiles[4]]==1][['m','pt','e','tau32','tau21','d23s']]\n",
    "\n",
    "x_train,x_test = x_train[:5000],x_train[5000:10000]\n",
    "y_train,y_test = y_train[:5000],y_train[5000:10000]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# To Do\n",
    "\n",
    "* Choose an optimal transport loss\n",
    "    * Measure distances within the same quantiles (x_train and x_test), (y_train and y_test) and compare to the training pairings (x and y)\n",
    "    * It should be differentiable!\n",
    "    * Train on pointcloud (batch of x to batch of y)\n",
    "    * Learns based on distributions\n",
    "* Could we also do an A to B map where now we aren't looking at point clouds but one to one mapping\n",
    "    * Shuffle all events together from side bands at each epoch and pair x_test+y_test shuffled into lowermass_test and highermass_test\n",
    "        * Definitely makes the SR an interpolation region and not soft extrapolation as minimum mass shift will be to transform an event to a mass point still within the same sideband\n",
    "        * Or keep the x<->y setup and define the \"closest\" point in the target as the target\n",
    "        * Or keep x<->y setup and randomly choose one of the target events as the target on each pass\n",
    "    * Each epoch is shuffled so seeing all possible points, the minimum would be to learn f(x|m)\n",
    "    * Learns based on individual transformations instead of learning over distributions\n",
    "* Choose an architecture\n",
    "    * Invertible Flows are our best choice\n",
    "        * N to N mapping: we should maintain correlations here as the transformation should be a small displacement\n",
    "        * Bidirectional: we have the same network for each side bands, this reduces our validation required and source of issues. The signal region will be an interpolation region\n",
    "        * Conditional INN possible: we can use the initial and target mass as the conditions (plus jet pT perhaps)\n",
    "            * Optimising the condition is key: we want to keep the signal window as an interpolation task for the flow model rather than be extrapolation:\n",
    "                * If we use m1 and m2 then m1 will be in SB1 and m2 will be in SB2, no SR masses will ever be seen\n",
    "                * m2 - m1 will always be bigger than m2 - mSR and mSR - m1\n",
    "* Get some simple tests done\n",
    "    * We can focus on a single directional flow to start with, can we conditionally transform an event to what it would have looked like at another mass point?\n",
    "    * We can use the SR as validation for all these studies, as well as additional mass quantiles\n",
    "    \n",
    "Another point to consider is that if we use optimal transport, each \"dimension\" is not necessarily equivalent. tau32 looks different to d23s. Would we want to have an INN to \"project\" events onto a manifold, we do the transformation here, and then transform back with the inverse of the network. I think this is overcomplicating things."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Name\n",
    "\n",
    "The project needs a good name, and I will try to make CURTAINs work, because all windows need curtains, even signal windows and sliding windows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}